services:
  spark:
    version: 2.3.1
    # git-commit: latest  # if not 'latest', provide a full commit SHA; e.g. d6dc12ef0146ae409834c78737c116050961f350
    # git-repository:  # optional; defaults to https://github.com/apache/spark
    # optional; defaults to download from from the official Spark S3 bucket
    #   - must contain a {v} template corresponding to the version
    #   - Spark must be pre-built
    #   - must be a tar.gz file
    # download-source: "https://www.example.com/files/spark/{v}/spark-{v}.tar.gz"
    #download-source: "https://s3-us-gov-west-1.amazonaws.com/clusterfiles/spark-2.3.1-bin-hadoop2.7.tgz"
    #download-source: "s3://clusterfiles/spark-{v}-bin-hadoop2.7.tgz"


    # executor-instances: 1
  hdfs:
    version: 2.8.4
    # optional; defaults to download from a dynamically selected Apache mirror
    #   - must contain a {v} template corresponding to the version
    #   - must be a .tar.gz file
    # download-source: "https://www.example.com/files/hadoop/{v}/hadoop-{v}.tar.gz"
    # download-source: "http://www-us.apache.org/dist/hadoop/common/hadoop-{v}/hadoop-{v}.tar.gz"

provider: ec2

providers:
  ec2:
    key-name: your-keyname
    identity-file: /path/to/your/key
    instance-type: m4.large
    region: us-gov-west-1
    # availability-zone: <name>
    ami: #ami-3ac75e5b #flintrock-server-231 #using a custom ami 
         ami-8578e4e4 #us-gov-west-1 #ami-7105540e   # Amazon Linux 2, us-east-1
    user: ec2-user
    # ami: ami-61bbf104   # CentOS 7, us-east-1
    # user: centos
    # spot-price: <price>
    # vpc-id: <id>
    # subnet-id: <id>
    # placement-group: <name>
    security-groups:
       - flintrock
    #   - group-name2
    instance-profile-name:  EMR_EC2_DefaultRole 
    # tags:
    #   - key1,value1
    #   - key2, value2  # leading/trailing spaces are trimmed
    #   - key3,  # value will be empty
    # min-root-ebs-size-gb: <size-gb>
    tenancy: default  # default | dedicated
    ebs-optimized: no  # yes | no
    instance-initiated-shutdown-behavior: terminate  # terminate | stop
    # user-data: /path/to/userdata/script

launch:
  num-slaves: 1
#using custom AMI with pre-installed libs, should be faster!
  install-hdfs: False #True
  install-spark: True #False

debug: true #false
